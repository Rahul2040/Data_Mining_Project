{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df created\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"Processing...\")\n",
    "\n",
    "engine = create_engine(\"mysql+mysqlconnector://root:password123@localhost/dmdb\")\n",
    "\n",
    "query = \"SELECT * FROM nltk_filtered_3_class\"\n",
    "df = pd.read_sql(query, engine)\n",
    "print(\"df created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   listing_id       id        date  reviewer_id reviewer_name  \\\n",
      "0        2595    19760  2009-12-10        38960         Anita   \n",
      "1        2595    34320  2010-04-09        71130       Kai-Uwe   \n",
      "2        2595    46312  2010-05-25       117113        Alicia   \n",
      "3        2595  1238204  2012-05-07      1783688        Sergey   \n",
      "4        2595  1293632  2012-05-17      1870771          Loïc   \n",
      "\n",
      "                                            comments  \\\n",
      "0  I've stayed with my friend at the Midtown Cast...   \n",
      "1  We've been staying here for about 9 nights, en...   \n",
      "2  We had a wonderful stay at Jennifer's charming...   \n",
      "3  Hi to everyone!\\r<br/>Would say our greatest c...   \n",
      "4  Jennifer was very friendly and helpful, and he...   \n",
      "\n",
      "                                 comments_without_br  Sentiment  \n",
      "0  ive stay friend midtown castl six day love pla...          1  \n",
      "1  weve stay 9 night enjoy center citi never slee...          1  \n",
      "2  wonder stay jennif charm apart organ help woul...          1  \n",
      "3  hi everyon would say greatest compliment jenni...          1  \n",
      "4  jennif friendli help place exactli advertis lo...          1  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_path = 'dictionary.txt'\n",
    "dictionary_words_list = pd.read_csv(dictionary_path, header=None)[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=df[['comments_without_br', 'Sentiment']]\n",
    "train_df=train_df.rename(columns={'comments_without_br':'text','Sentiment':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df[0:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train samples =  100000\n",
      "Dictionary size =  1000\n",
      "Number of instances for each label:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "label       \n",
       "-1      1555\n",
       " 0      7774\n",
       " 1     90671"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Number of Train samples = \", train_df.shape[0])\n",
    "\n",
    "print(\"Dictionary size = \", len(dictionary_words_list))\n",
    "print(\"Number of instances for each label:\")\n",
    "display(train_df[['text', 'label']].groupby(by='label').agg('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def get_tokens(text):\n",
    "    \"\"\"\n",
    "        Perform lowercase, punctuation and stopword removal, tokenization\n",
    "        and finally stemming to get tokens from given text\n",
    "    \"\"\"\n",
    "    lowers = text.lower()\n",
    "    no_punctuation = lowers.translate(remove_punctuation_map)\n",
    "    tokens = nltk.word_tokenize(no_punctuation)\n",
    "    filtered = [w for w in tokens if not w in stopwords.words(\"english\")]\n",
    "    stemmed = []\n",
    "    for item in filtered:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data Mining\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "tf = CountVectorizer(tokenizer=get_tokens, vocabulary=dictionary_words_list)\n",
    "train_tf = tf.fit_transform(train_df['text']).toarray()\n",
    "# test_tf = tf.transform(test_df['Text']).toarray()\n",
    "print(\"done\")\n",
    "tfidf = TfidfVectorizer(tokenizer=get_tokens, vocabulary=dictionary_words_list)\n",
    "train_tfidf = tfidf.fit_transform(train_df['text']).toarray()\n",
    "# test_tfidf = tfidf.transform(test_df['Text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "k = 50\n",
    "frequency = False\n",
    "binarize = False\n",
    "category_wise = True\n",
    "sel_freq_mat = train_tfidf\n",
    "\n",
    "# features = get_topk_words(sel_freq_mat, k, category_wise)\n",
    "features = np.arange(len(dictionary_words_list))\n",
    "\n",
    "# train_matrix, test_matrix = train_tfidf, test_tfidf\n",
    "train_matrix  =train_tfidf\n",
    "X = train_matrix[:, features]\n",
    "# X_test = test_matrix[:, features]\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluator(X_train, y_train, clf_type, cv_param_name, cv_param_values, n_splits=5, init_params={}):\n",
    "    \"\"\"\n",
    "        Perform K-Fold cross validation and collate\n",
    "        results for each value, split combination\n",
    "    \"\"\"\n",
    "    clf_type_dict={\n",
    "        'Decision Tree': DecisionTreeClassifier(**init_params, random_state=seed),\n",
    "        'Random Forest': RandomForestClassifier(**init_params, random_state=seed)\n",
    "    }\n",
    "    requested_clf=clf_type_dict[clf_type]\n",
    "\n",
    "    eval_df = pd.DataFrame(columns=[cv_param_name, \"Split Id\", \"Train Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    for cv_param_val in cv_param_values:\n",
    "        for i, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "            requested_clf.set_params(**{cv_param_name: cv_param_val})\n",
    "            requested_clf.fit(X_train[train_idx], y_train[train_idx])\n",
    "            train_acc = accuracy_score(y_train[train_idx], requested_clf.predict(X_train[train_idx]))\n",
    "            val_acc = accuracy_score(y_train[val_idx], requested_clf.predict(X_train[val_idx]))\n",
    "            eval_df.loc[eval_df.shape[0]] = [cv_param_val, i, train_acc, val_acc]\n",
    "    \n",
    "    return eval_df\n",
    "\n",
    "def plot_eval(eval_df, cv_param_name, clf_type, figsize=(8,5)):\n",
    "    \"\"\"\n",
    "        Line plot for K-Fold cross validation results\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=figsize)\n",
    "    sns.lineplot(data=eval_df, x=cv_param_name, y='Train Accuracy', ax=ax, label=\"Train Accuracy\")\n",
    "    sns.lineplot(data=eval_df, x=cv_param_name, y='Validation Accuracy', ax=ax, label=\"Validation Accuracy\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(clf_type + \": \" + cv_param_name + \" vs Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "criterion = ['gini', 'entropy']\n",
    "res = {c : [] for c in criterion}\n",
    "for c in criterion:\n",
    "    clf = DecisionTreeClassifier(criterion=c)\n",
    "    clf.fit(X_train, y_train)\n",
    "    res[c].append(accuracy_score(y_train, clf.predict(X_train)))\n",
    "    res[c].append(accuracy_score(y_val, clf.predict(X_val)))\n",
    "ax = pd.DataFrame(res, index=[\"Train Accuracy\", \"Validation Accuracy\"]).plot.bar(rot=0)\n",
    "_, _ = ax.bar_label(ax.containers[0], fmt=\"%.2f\"), ax.bar_label(ax.containers[1], fmt=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.37      0.39       304\n",
      "           0       0.36      0.28      0.31      1570\n",
      "           1       0.93      0.95      0.94     18126\n",
      "\n",
      "    accuracy                           0.89     20000\n",
      "   macro avg       0.57      0.53      0.55     20000\n",
      "weighted avg       0.88      0.89      0.88     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, clf.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "X_train_sparse=csr_matrix(X_train)\n",
    "X_val_sparse=csr_matrix(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data Mining\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.9052 - loss: 0.2793 - val_accuracy: 0.9014 - val_loss: 0.1796\n",
      "Epoch 2/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8974 - loss: 0.1648 - val_accuracy: 0.8964 - val_loss: 0.1555\n",
      "Epoch 3/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8949 - loss: 0.1331 - val_accuracy: 0.8856 - val_loss: 0.1287\n",
      "Epoch 4/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8919 - loss: 0.1165 - val_accuracy: 0.8870 - val_loss: 0.0985\n",
      "Epoch 5/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.8927 - loss: 0.0422 - val_accuracy: 0.8880 - val_loss: 0.0582\n",
      "Epoch 6/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8906 - loss: 0.0034 - val_accuracy: 0.8935 - val_loss: 0.0131\n",
      "Epoch 7/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8918 - loss: -0.0455 - val_accuracy: 0.8858 - val_loss: -0.0521\n",
      "Epoch 8/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8908 - loss: -0.1973 - val_accuracy: 0.8912 - val_loss: -0.1395\n",
      "Epoch 9/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8885 - loss: -0.3026 - val_accuracy: 0.8887 - val_loss: -0.2389\n",
      "Epoch 10/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.8891 - loss: -0.4757 - val_accuracy: 0.8902 - val_loss: -0.3566\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8877 - loss: -0.3675\n",
      "Test Accuracy: 89.02%\n"
     ]
    }
   ],
   "source": [
    "X_train_seq = pad_sequences(X_train_sparse.toarray(), dtype='float32')\n",
    "X_test_seq = pad_sequences(X_val_sparse.toarray(), dtype='float32')\n",
    "\n",
    "X_train_seq = X_train_seq.reshape(X_train_seq.shape[0], 1, X_train_seq.shape[1])\n",
    "X_test_seq = X_test_seq.reshape(X_test_seq.shape[0], 1, X_test_seq.shape[1])\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_seq, y_train, epochs=10, batch_size=32, validation_data=(X_test_seq, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_seq, y_val)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : LSTM\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       304\n",
      "           0       0.33      0.33      0.33      1570\n",
      "           1       0.94      0.95      0.95     18126\n",
      "\n",
      "    accuracy                           0.89     20000\n",
      "   macro avg       0.42      0.43      0.43     20000\n",
      "weighted avg       0.88      0.89      0.88     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data Mining\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Data Mining\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Data Mining\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Model : LSTM\")\n",
    "y_pred_probs = model.predict(X_test_seq)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Calculate precision, recall, F1-score, support\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m svm_model \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the SVM model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43msvm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m svm_model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[1;32md:\\Data Mining\\venv\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Data Mining\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32md:\\Data Mining\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    319\u001b[0m (\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_weight_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the SVM model\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm_model.predict(X_val)\n",
    "print(\"Model: Support Vector Machine\")\n",
    "# Calculate precision, recall, F1-score, support\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_gridsearch(X_train, y_train, base_clf, param_grid):\n",
    "    clf_grid = GridSearchCV(\n",
    "        estimator=base_clf,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='f1_micro',\n",
    "        n_jobs=8,\n",
    "        refit=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    clf_grid.fit(X, y)\n",
    "\n",
    "    return clf_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \n",
    "    'Random Forests': {\n",
    "        'model': RandomForestClassifier(criterion='gini', warm_start=True, random_state=41),\n",
    "        'param_grid': {\n",
    "            'n_estimators': [150],\n",
    "            'min_samples_leaf': [10] ,\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for myModel in models.keys():\n",
    "    print(f\"Model Type: {myModel}\")\n",
    "    models[myModel]['clf_grid'] = eval_gridsearch(X, y, models[myModel]['model'], models[myModel]['param_grid'])\n",
    "    print(\"Best Hyperparameters achieved: \", models[myModel]['clf_grid'].best_params_)\n",
    "    print(\"F1-Micro Score = \", models[myModel]['clf_grid'].best_score_)\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = logreg.predict(X_val)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load IMDb movie reviews dataset (or any other sentiment analysis dataset)\n",
    "# Assume X_train, y_train, X_test, y_test are loaded with text and corresponding sentiment labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df['text'], train_df['label'], test_size=0.2, random_state=100)\n",
    "# Tokenize input texts using BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "X_train_tokens = tokenizer.batch_encode_plus(X_train, max_length=128, padding='max_length', truncation=True, return_tensors='pt')\n",
    "X_test_tokens = tokenizer.batch_encode_plus(X_test, max_length=128, padding='max_length', truncation=True, return_tensors='pt')\n",
    "\n",
    "# Convert sentiment labels to tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_train.to_list())\n",
    "\n",
    "y_train_list=y_train.to_list()\n",
    "y_train_list=list(map(lambda x:x+1,y_train_list ))\n",
    "\n",
    "y_test_list=y_test.to_list()\n",
    "y_test_list=list(map(lambda x:x+1,y_test_list ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train_list)\n",
    "y_test_tensor = torch.tensor(y_test_list)\n",
    "\n",
    "\n",
    "# y_train_tensor = torch.tensor(y_train.to_list())\n",
    "# y_test_tensor = torch.tensor(y_test.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create DataLoader for training and testing datasets\n",
    "train_dataset = TensorDataset(X_train_tokens['input_ids'], X_train_tokens['attention_mask'], y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test_tokens['input_ids'], X_test_tokens['attention_mask'], y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Load pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)  # assuming binary classification\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device='cpu'\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    count=0\n",
    "    for batch in train_loader:\n",
    "        print(f\"\\r{count} of {len(train_loader)}\",end=\"\")\n",
    "        count+=1\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for batch in test_loader:\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for batch in test_loader:\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
